{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ReconNER, Debug annotated Named Entity Recognition (NER) data for inconsitencies and get insights on improving the quality of your data. Documentation : https://microsoft.github.io/reconner Source Code : https://github.com/microsoft/reconner ReconNER is a library to help you fix your annotated NER data and identify examples that are hardest for your model to predict so you can strategically prioritize the examples you annotate. The key features are: Data Validation and Cleanup : Easily Validate the format of your NER data. Filter overlapping Entity Annotations, fix missing properties. Model Insights : Analyze how well your model does on your Dataset. Identify the top errors your model is making so you can prioritize data collection and correction strategically. Model Insights : Analyze how well your model does on your Dataset. Identify the top errors your model is making so you can prioritize data collection and correction strategically. Dataset Management : reconner provides a Dataset class to manage the train/dev/test split of your data and apply the same functions across all splits in your data + a concatenation of all examples. Operate inplace to consistently transform your data. Serializable Dataset : Serialize and Deserialize your data to and from JSON to the reconner type system. Type Hints : Comprehensive Typing system based on Python 3.6+ Type Hints Requirements \u00b6 Python 3.6+ Python 3.6+ ReconNER is built on a few comprehensive, high-performing packages. spaCy Pydantic (Type system and JSON Serialization) Typer (CLI) . Installation \u00b6 $ pip install reconner ---> 100% Successfully installed reconner License \u00b6 This project is licensed under the terms of the MIT license.","title":"Introduction"},{"location":"#requirements","text":"Python 3.6+ Python 3.6+ ReconNER is built on a few comprehensive, high-performing packages. spaCy Pydantic (Type system and JSON Serialization) Typer (CLI) .","title":"Requirements"},{"location":"#installation","text":"$ pip install reconner ---> 100% Successfully installed reconner","title":"Installation"},{"location":"#license","text":"This project is licensed under the terms of the MIT license.","title":"License"},{"location":"contributing/","text":"Contributing \u00b6 This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Development - Contributing"},{"location":"contributing/#contributing","text":"This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contributing"},{"location":"features/","text":"Design based on FastAPI \u00b6 Typer is FastAPI 's little sibling. It follows the same design and ideas. If you know FastAPI, you already know Typer ... more or less. Just Modern Python \u00b6 It's all based on standard Python 3.6 type declarations. No new syntax to learn. Just standard modern Python. If you need a 2 minute refresher of how to use Python types (even if you don't use FastAPI or Typer), check the FastAPI tutorial section: Python types intro . Editor support \u00b6 Typer was designed to be easy and intuitive to use, to ensure the best development experience. With autocompletion everywhere. You will rarely need to come back to the docs. Here's how your editor might help you: in Visual Studio Code : in PyCharm : You will get completion for everything. That's something no other CLI library provides right now. No more guessing what type was that variable, if it could be None , etc. Short \u00b6 It has sensible defaults for everything, with optional configurations everywhere. All the parameters can be fine-tuned to do what you need, customize the help, callbacks per parameter, make them required or not, etc. But by default, it all \"just works\" . User friendly CLI apps \u00b6 The resulting CLI apps created with Typer have the nice features of many \"pro\" command line programs you probably already love. Automatic help options for the main CLI program and all the its subcommands. Automatic command and subcommand structure handling (you will see more about subcommands in the Tutorial - User Guide). Automatic autocompletion for the CLI app in all operating systems, in all the shells (Bash, Zsh, Fish, PowerShell), so that the final user of your app can just hit TAB and get the available options or subcommands. * * Autocompletion For the autocompletion to work on all shells you also need to add the dependency click-completion . Just that. And Typer does the rest. If Typer detects click-completion installed, it will automatically create 2 CLI options : --install-completion : Install completion for the current shell. --show-completion : Show completion for the current shell, to copy it or customize the installation. Then you can tell the user to run that command and the rest will just work. The power of Click \u00b6 Click is one of the most popular tools for building CLIs in Python. Typer is based on it, so you get all its benefits, plug-ins, robustness, etc. But you can write simpler code with the benefits of modern Python.","title":"Features"},{"location":"features/#design-based-on-fastapi","text":"Typer is FastAPI 's little sibling. It follows the same design and ideas. If you know FastAPI, you already know Typer ... more or less.","title":"Design based on FastAPI"},{"location":"features/#just-modern-python","text":"It's all based on standard Python 3.6 type declarations. No new syntax to learn. Just standard modern Python. If you need a 2 minute refresher of how to use Python types (even if you don't use FastAPI or Typer), check the FastAPI tutorial section: Python types intro .","title":"Just Modern Python"},{"location":"features/#editor-support","text":"Typer was designed to be easy and intuitive to use, to ensure the best development experience. With autocompletion everywhere. You will rarely need to come back to the docs. Here's how your editor might help you: in Visual Studio Code : in PyCharm : You will get completion for everything. That's something no other CLI library provides right now. No more guessing what type was that variable, if it could be None , etc.","title":"Editor support"},{"location":"features/#short","text":"It has sensible defaults for everything, with optional configurations everywhere. All the parameters can be fine-tuned to do what you need, customize the help, callbacks per parameter, make them required or not, etc. But by default, it all \"just works\" .","title":"Short"},{"location":"features/#user-friendly-cli-apps","text":"The resulting CLI apps created with Typer have the nice features of many \"pro\" command line programs you probably already love. Automatic help options for the main CLI program and all the its subcommands. Automatic command and subcommand structure handling (you will see more about subcommands in the Tutorial - User Guide). Automatic autocompletion for the CLI app in all operating systems, in all the shells (Bash, Zsh, Fish, PowerShell), so that the final user of your app can just hit TAB and get the available options or subcommands. * * Autocompletion For the autocompletion to work on all shells you also need to add the dependency click-completion . Just that. And Typer does the rest. If Typer detects click-completion installed, it will automatically create 2 CLI options : --install-completion : Install completion for the current shell. --show-completion : Show completion for the current shell, to copy it or customize the installation. Then you can tell the user to run that command and the rest will just work.","title":"User friendly CLI apps"},{"location":"features/#the-power-of-click","text":"Click is one of the most popular tools for building CLIs in Python. Typer is based on it, so you get all its benefits, plug-ins, robustness, etc. But you can write simpler code with the benefits of modern Python.","title":"The power of Click"},{"location":"release-notes/","text":"0.0.1 \u00b6 First commit. Publish to PyPI to reserve package name. Initial Functionality for Validation, Insights, Dataset Managment, Serialization and Deserialization from JSON files, Type System","title":"Release Notes"},{"location":"release-notes/#001","text":"First commit. Publish to PyPI to reserve package name. Initial Functionality for Validation, Insights, Dataset Managment, Serialization and Deserialization from JSON files, Type System","title":"0.0.1"},{"location":"api/dataset/","text":"reconner.dataset.Dataset \u00b6 reconner.dataset.Dataset is a container to run other reconner operations across your train/dev/test split The reconner.dataset.Dataset.apply function takes any of the other reconner functions and runs them on all the datasets in sequence. API \u00b6 class reconner. Dataset ( train , dev , test=None ) Container for a full dataset with train/dev/test splits. Used to apply core functions to all datasets at once. Parameters \u00b6 train : (List[Example]), required. List of Examples for train set dev : (List[Example]), required. List of Examples for dev set test : (List[Example], optional), Defaults to None. List of Examples for test set apply ( self , func , *args , **kwargs ) Apply an existing function to all datasets Parameters \u00b6 func : (Callable[[List[Example]], Any]), required. Function from an existing reconner module that can operate on a List of Examples Returns \u00b6 (Dict[str, List[Example]]): Dictionary mapping dataset names to List [ Example ] , same as the internal datasets property from_disk ( path , loader_func= ) Load Dataset from disk given a directory with files named explicitly train.jsonl, dev.jsonl, and test.jsonl Parameters \u00b6 path : (Path), required. directory to load from loader_func : (Callable, optional), Defaults to read_jsonl. Loader function (TODO: Make this a bit more generic)","title":"Dataset"},{"location":"api/dataset/#reconnerdatasetdataset","text":"reconner.dataset.Dataset is a container to run other reconner operations across your train/dev/test split The reconner.dataset.Dataset.apply function takes any of the other reconner functions and runs them on all the datasets in sequence.","title":"reconner.dataset.Dataset"},{"location":"api/dataset/#api","text":"class reconner. Dataset ( train , dev , test=None ) Container for a full dataset with train/dev/test splits. Used to apply core functions to all datasets at once.","title":"API"},{"location":"api/insights/","text":"reconner.insights \u00b6 The reconner.insights module provides more complex functionality for understanding your dataset. It provides functions for identifying disparities in your annotations and identifying the kinds of examples and labels that are hardest for your model to identify. Some of the functionality in reconner.insights require a reconner.recognizer.EntityRecognizer object. You can read more about the EntityRecognizer class here: Tutorial - Custom EntityRecognizer API \u00b6 reconner.insights. ents_by_label ( data , use_lower=True ) Get a dictionary of unique text spans by label for your data Parameters \u00b6 data : (List[Example]), required. List of Examples use_lower : (bool, optional), Defaults to True. Use the lowercase form of the span text Returns \u00b6 (DefaultDict[str, List[str]]): DefaultDict mapping label to sorted list of the unique spans annotated for that label . reconner.insights. get_label_disparities ( data , label1 , label2 , use_lower=True ) Identify annotated spans that have different labels in different examples Parameters \u00b6 data : (List[Example]), required. Input List of Examples label1 : (str), required. First label to compare label2 : (str), required. Second label to compare Returns \u00b6 (Set[str]): Set of all unique text spans that overlap between label1 and label2 reconner.insights. top_prediction_errors ( ner , data , labels=None , k=None , exclude_fp=False , exclude_fn=False ) Get a sorted list of examples your model is worst at predicting. Parameters \u00b6 ner : (EntityRecognizer), required. An instance of EntityRecognizer data : (List[Example]), required. List of annotated Examples labels : (List[str], optional), Defaults to None. List of labels to get errors for . Defaults to the labels property of ner . k : (int, optional), Defaults to None. If set, return the top k prediction errors, otherwise the whole list. exclude_fp : (bool, optional), Defaults to False. Flag to exclude False Positive errors. exclude_fn : (bool, optional), Defaults to False. Flag to exclude False Negative errors. Returns \u00b6 (List[PredictionError]): [ description ]","title":"Insights"},{"location":"api/insights/#reconnerinsights","text":"The reconner.insights module provides more complex functionality for understanding your dataset. It provides functions for identifying disparities in your annotations and identifying the kinds of examples and labels that are hardest for your model to identify. Some of the functionality in reconner.insights require a reconner.recognizer.EntityRecognizer object. You can read more about the EntityRecognizer class here: Tutorial - Custom EntityRecognizer","title":"reconner.insights"},{"location":"api/insights/#api","text":"reconner.insights. ents_by_label ( data , use_lower=True ) Get a dictionary of unique text spans by label for your data","title":"API"},{"location":"api/stats/","text":"reconner.stats \u00b6 The stats module implements utility functions for getting statistics for an NER dataset. It's useful for getting a quick overview of your data and checking that you have enough examples for each label (including examples with NO ENTITIES ) API \u00b6 ner_stats \u00b6 reconner.stats. ner_stats ( data , serialize=False , no_print=False ) Compute statistics for NER data Parameters \u00b6 data : (List[Example]), required. Data as a List of Examples serialize : (bool, optional), Defaults to False. Serialize to a JSON string for printing no_print : (bool, optional), Defaults to False. Don't print, return serialized string. Requires serialize to be True Returns \u00b6 (List[Example]): List of examples or string if serialize and no_print are both True","title":"Stats"},{"location":"api/stats/#reconnerstats","text":"The stats module implements utility functions for getting statistics for an NER dataset. It's useful for getting a quick overview of your data and checking that you have enough examples for each label (including examples with NO ENTITIES )","title":"reconner.stats"},{"location":"api/stats/#api","text":"","title":"API"},{"location":"api/stats/#ner_stats","text":"reconner.stats. ner_stats ( data , serialize=False , no_print=False ) Compute statistics for NER data","title":"ner_stats"},{"location":"api/validation/","text":"reconner.validation \u00b6 reconner.validation provides a set of utility functions to fix and validate annotations to ensure consistency and no overlapping entities are set. These functions are useful to run before any of the functionality in reconner.insights or reconner.stats . API \u00b6 json_to_examples \u00b6 reconner.validation. json_to_examples ( data ) Convert List of Dicts to List of typed Examples Parameters \u00b6 data : (List[Dict[str, Any]]), required. Input List of Dicts to convert Returns \u00b6 (List[Example]): List of typed Examples fix_annotations_format \u00b6 reconner.validation. fix_annotations_format ( data ) Fix annotations format for a consistent dataset Parameters \u00b6 data : (List[Dict[str, Any]]), required. List of Examples Returns \u00b6 (List[Dict[str, Any]]): List of Examples with corrected formatting filter_overlaps \u00b6 reconner.validation. filter_overlaps ( data ) Filter overlapping entity spans by picking the longest one. Parameters \u00b6 data : (List[Dict[str, Any]]), required. List of Examples Returns \u00b6 (List[Dict[str, Any]]): List of Examples with fixed overlaps","title":"Validation"},{"location":"api/validation/#reconnervalidation","text":"reconner.validation provides a set of utility functions to fix and validate annotations to ensure consistency and no overlapping entities are set. These functions are useful to run before any of the functionality in reconner.insights or reconner.stats .","title":"reconner.validation"},{"location":"api/validation/#api","text":"","title":"API"},{"location":"api/validation/#json_to_examples","text":"reconner.validation. json_to_examples ( data ) Convert List of Dicts to List of typed Examples","title":"json_to_examples"},{"location":"api/validation/#fix_annotations_format","text":"reconner.validation. fix_annotations_format ( data ) Fix annotations format for a consistent dataset","title":"fix_annotations_format"},{"location":"api/validation/#filter_overlaps","text":"reconner.validation. filter_overlaps ( data ) Filter overlapping entity spans by picking the longest one.","title":"filter_overlaps"},{"location":"tutorial/custom_entity_recognizer/","text":"Custom EntityRecognizer \u00b6","title":"Custom EntityRecognizer"},{"location":"tutorial/custom_entity_recognizer/#custom-entityrecognizer","text":"","title":"Custom EntityRecognizer"},{"location":"tutorial/loading_data/","text":"Loading your data \u00b6 ReconNER expects your data to be in the Prodigy Annotation Format . A single example in this format looks like: { \"text\" : \"Apple updates its analytics service with new metrics\" , \"spans\" : [{ \"start\" : 0 , \"end\" : 5 , \"label\" : \"ORG\" }] } ReconNER expects your data to be in a collection in the .jsonl File Format. Load Dataset from_disk \u00b6 There are several utilities available for loading your data. The easiest way to load your data is to initialize a Dataset from disk. If you have a train/dev/test split or just train/dev files in the same directory, it's as easy as calling the from_disk classmethod for the Dataset object. ds = Dataset . from_disk ( 'path/to/data_dir' ) Dataset.from_disk will look in the data_dir you provide for a file structure that looks like: data_dir \u2502 train.jsonl \u2502 dev.jsonl \u2502 test.jsonl Note The test.jsonl file is optional but generally you should split your annotated data into train/dev/test files. The Process of Loading Data \u00b6 While it's recommended to load data using the Dataset.from_disk method, you can also load data directly from disk using the loaders.read_jsonl and loaders.read_json functions. These functions expect the same example format (in fact, the Dataset.from_disk runs loaders.read_jsonl function) and run a few steps. 1. Read data from disk \u00b6 Loads your data with srsly using srsly.read_jsonl or srsly.read_json 2. Fix Annotation Format \u00b6 Fixes some common issues in Annotation formatting that can arise using the validation.fix_annotations_format 3. Filter Overlapping Entities \u00b6 Often, you'll find your data has overlapping entities. For instance, imagine you have 2 annotators and one decided \"Tesla\" is a PRODUCT and the other noticed that the sentence is actually about \"Tesla Motors\" which they label as an ORG . This function does it's best to resolve these overlaps and in the case above would select \"Tesla Motors\" ORG as the correct entity, deleting \"Tesla\" PRODUCT from the data validation.filter_overlaps 4. Load into ReconNER type system \u00b6 Finally these loaders will take a list of JSON examples in the Prodigy Annotation Format outlined above and convert it into a list of Example models using Pydantic Next Steps \u00b6 Once you have your data loaded, you can run other ReconNER functions on top of it to gain insights into the quality and completeness of your NER data","title":"Loading your data"},{"location":"tutorial/loading_data/#loading-your-data","text":"ReconNER expects your data to be in the Prodigy Annotation Format . A single example in this format looks like: { \"text\" : \"Apple updates its analytics service with new metrics\" , \"spans\" : [{ \"start\" : 0 , \"end\" : 5 , \"label\" : \"ORG\" }] } ReconNER expects your data to be in a collection in the .jsonl File Format.","title":"Loading your data"},{"location":"tutorial/loading_data/#load-dataset-from_disk","text":"There are several utilities available for loading your data. The easiest way to load your data is to initialize a Dataset from disk. If you have a train/dev/test split or just train/dev files in the same directory, it's as easy as calling the from_disk classmethod for the Dataset object. ds = Dataset . from_disk ( 'path/to/data_dir' ) Dataset.from_disk will look in the data_dir you provide for a file structure that looks like: data_dir \u2502 train.jsonl \u2502 dev.jsonl \u2502 test.jsonl Note The test.jsonl file is optional but generally you should split your annotated data into train/dev/test files.","title":"Load Dataset from_disk"},{"location":"tutorial/loading_data/#the-process-of-loading-data","text":"While it's recommended to load data using the Dataset.from_disk method, you can also load data directly from disk using the loaders.read_jsonl and loaders.read_json functions. These functions expect the same example format (in fact, the Dataset.from_disk runs loaders.read_jsonl function) and run a few steps.","title":"The Process of Loading Data"},{"location":"tutorial/loading_data/#1-read-data-from-disk","text":"Loads your data with srsly using srsly.read_jsonl or srsly.read_json","title":"1. Read data from disk"},{"location":"tutorial/loading_data/#2-fix-annotation-format","text":"Fixes some common issues in Annotation formatting that can arise using the validation.fix_annotations_format","title":"2. Fix Annotation Format"},{"location":"tutorial/loading_data/#3-filter-overlapping-entities","text":"Often, you'll find your data has overlapping entities. For instance, imagine you have 2 annotators and one decided \"Tesla\" is a PRODUCT and the other noticed that the sentence is actually about \"Tesla Motors\" which they label as an ORG . This function does it's best to resolve these overlaps and in the case above would select \"Tesla Motors\" ORG as the correct entity, deleting \"Tesla\" PRODUCT from the data validation.filter_overlaps","title":"3. Filter Overlapping Entities"},{"location":"tutorial/loading_data/#4-load-into-reconner-type-system","text":"Finally these loaders will take a list of JSON examples in the Prodigy Annotation Format outlined above and convert it into a list of Example models using Pydantic","title":"4. Load into ReconNER type system"},{"location":"tutorial/loading_data/#next-steps","text":"Once you have your data loaded, you can run other ReconNER functions on top of it to gain insights into the quality and completeness of your NER data","title":"Next Steps"},{"location":"tutorial/ner_stats/","text":"Tutorial - NER Statistics \u00b6 Getting statistics about your NER data is extremely helpful throughout the annotation process. It helps you ensure that you're spendind time on the right annotations and that you have enough examples for each type as well as enough examples with NO ENTITIES at all (this is often overlooked but VERY important to build a model that generalizes well). Once you have your data loaded either by itself as a list of Example s or as a Dataset you can easily get statistics using the stats.ner_stats funtion","title":"NER Stats"},{"location":"tutorial/ner_stats/#tutorial-ner-statistics","text":"Getting statistics about your NER data is extremely helpful throughout the annotation process. It helps you ensure that you're spendind time on the right annotations and that you have enough examples for each type as well as enough examples with NO ENTITIES at all (this is often overlooked but VERY important to build a model that generalizes well). Once you have your data loaded either by itself as a list of Example s or as a Dataset you can easily get statistics using the stats.ner_stats funtion","title":"Tutorial - NER Statistics"}]}